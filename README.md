# I AM DATA ENGINEERING TODDLER

> **ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ì…ë¬¸ë¶€í„° ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ê¹Œì§€.**
> 
> ì´ í”„ë¡œì íŠ¸ëŠ” Docker í™˜ê²½ ìœ„ì—ì„œ **ìˆ˜ì§‘(Collect) -> ì ì¬(Ingest) -> ë³€í™˜(Transform) -> ì‹œê°í™”(Visualize)** ë¡œ ì´ì–´ì§€ëŠ” ì „ì²´ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ì§ì ‘ êµ¬ì¶•í•´ë³´ë©° í•™ìŠµí•œ ê¸°ë¡ì…ë‹ˆë‹¤.

<p align="center">
  <img src="img/toddler.png" alt="toddler image" width="300">
</p>

## ğŸ—ï¸ Project Architecture

ì´ í”„ë¡œì íŠ¸ëŠ” ë¡œì»¬ Docker í™˜ê²½ì—ì„œ ë‹¤ìŒ ê¸°ìˆ  ìŠ¤íƒë“¤ì„ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ë™ì‘í•©ë‹ˆë‹¤.

| ì˜ì—­ | ê¸°ìˆ  ìŠ¤íƒ | ì—­í•  |
| :--- | :--- | :--- |
| **Infra** | ![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=Docker&logoColor=white) | ì „ì²´ ì„œë¹„ìŠ¤ ì»¨í…Œì´ë„ˆí™” ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (Docker Compose) |
| **Orchestration** | ![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat-square&logo=Apache%20Airflow&logoColor=white) | ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§ |
| **Processing** | ![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=flat-square&logo=Apache%20Spark&logoColor=white) | ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬ (PySpark) & ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ |
| **Streaming** | ![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=flat-square&logo=Apache%20Kafka&logoColor=white) | ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ë° ë©”ì‹œì§€ ë¸Œë¡œí‚¹ |
| **Storage** | ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=flat-square&logo=PostgreSQL&logoColor=white) | ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤ (DW) ë° ë©”íƒ€ë°ì´í„° ì €ì¥ì†Œ |
| **Transformation** | ![dbt](https://img.shields.io/badge/dbt-FF694B?style=flat-square&logo=dbt&logoColor=white) | SQL ê¸°ë°˜ì˜ ë°ì´í„° ëª¨ë¸ë§ ë° ë³€í™˜ (ELT) |
| **Visualization** | ![Metabase](https://img.shields.io/badge/Metabase-509EE3?style=flat-square&logo=Metabase&logoColor=white) | ìµœì¢… ë°ì´í„° ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ êµ¬ì¶• |

## ğŸš€ Roadmap & Documentation

ì´ í”„ë¡œì íŠ¸ëŠ” ì´ 5ë‹¨ê³„ë¡œ ì§„í–‰ë˜ì—ˆìœ¼ë©°, ê° ë‹¨ê³„ë³„ ìƒì„¸í•œ êµ¬ì¶• ê³¼ì •ê³¼ í•™ìŠµ ë‚´ìš©ì€ ì•„ë˜ ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### [Step 1: í™˜ê²½ êµ¬ì¶• (Environment Setup)](./docs/01.%20Docker%2C%20Airflow%2C%20Postgresë¡œ%20ê°œë°œ%20í™˜ê²½%20êµ¬ì¶•í•˜ê¸°.md)
- `docker-compose`ë¥¼ í™œìš©í•˜ì—¬ Airflow, Postgres ë“± ê¸°ë³¸ ì¸í”„ë¼ êµ¬ì¶•
- Airflow ì´ˆê¸° ì„¤ì • ë° DB(Data Warehouse) ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ìë™í™”

### [Step 2: Modern ELT Pipeline](./docs/02.%20Airflowì™€%20dbtë¡œ%20ELT%20íŒŒì´í”„ë¼ì¸%20êµ¬ì¶•í•˜ê¸°.md)
- **Extract/Load:** Python(Pandas)ì„ ì´ìš©í•´ CSV ë°ì´í„°ë¥¼ Postgresë¡œ ì ì¬
- **Transform:** `dbt`ë¥¼ Airflowì™€ ì—°ë™í•˜ì—¬ `raw` -> `stg` -> `mart` ë ˆì´ì–´ë¡œ ë°ì´í„° ë³€í™˜

### [Step 3: Big Data Batch Processing](./docs/03.%20PySparkë¥¼%20í™œìš©í•œ%20ëŒ€ìš©ëŸ‰%20ë°°ì¹˜%20ì²˜ë¦¬.md)
- **Processing:** Pandasë¥¼ **PySpark**ë¡œ ëŒ€ì²´í•˜ì—¬ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
- **Driver/Worker:** Spark Standalone Cluster(Master/Worker) êµ¬ì¶• ë° Airflow ì—°ë™ (`SparkSubmitOperator`)

### [Step 4: Real-time Streaming](./docs/04.%20Kafkaì™€%20Spark%20Streamingì„%20ì´ìš©í•œ%20ì‹¤ì‹œê°„%20ë°ì´í„°%20ì²˜ë¦¬.md)
- **Source:** Python ìŠ¤í¬ë¦½íŠ¸ë¡œ CSV ë°ì´í„°ë¥¼ 1ì´ˆ ë‹¨ìœ„ë¡œ **Kafka** í† í”½ì— ì „ì†¡ (Producer)
- **Sink:** **Spark Structured Streaming**ì„ ì´ìš©í•´ Kafka ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì†Œë¹„(Consumer) ë° ì§‘ê³„

### [Step 5: BI & Visualization](./docs/05.%20Metabaseë¥¼%20í™œìš©í•œ%20ë°ì´í„°%20ì‹œê°í™”%20(BI)%20êµ¬ì¶•.md)
- **Metabase**ë¥¼ ë„ì»¤ì— ì¶”ê°€í•˜ì—¬ Postgres DWì™€ ì—°ë™
- `dbt`ë¡œ ìƒì„±ëœ Mart ë°ì´í„°ë¥¼ í™œìš©í•´ í™˜ì ë°©ë¬¸ í˜„í™© ì‹œê°í™” ëŒ€ì‹œë³´ë“œ êµ¬í˜„

## ğŸ“‚ Directory Structure

```bash
.
â”œâ”€â”€ dags/                   # Airflow DAG íŒŒì¼
â”‚   â”œâ”€â”€ elt_patient_pipeline.py
â”‚   â””â”€â”€ elt_spark_pipeline.py
â”œâ”€â”€ data/                   # ì›ë³¸ ë°ì´í„° (CSV)
â”‚   â””â”€â”€ patient_treatment.csv
â”œâ”€â”€ dbt/                    # dbt í”„ë¡œì íŠ¸ (Models, Config)
â”‚   â”œâ”€â”€ macros/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ profiles.yml
â”œâ”€â”€ docs/                   # ë‹¨ê³„ë³„ ìƒì„¸ í•™ìŠµ ë¬¸ì„œ (Markdown)
â”‚   â”œâ”€â”€ 01. Docker, Airflow, Postgresë¡œ ê°œë°œ í™˜ê²½ êµ¬ì¶•í•˜ê¸°.md
â”‚   â”œâ”€â”€ 02. Airflowì™€ dbtë¡œ ELT íŒŒì´í”„ë¼ì¸ êµ¬ì¶•í•˜ê¸°.md
â”‚   â”œâ”€â”€ 03. PySparkë¥¼ í™œìš©í•œ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬.md
â”‚   â”œâ”€â”€ 04. Kafkaì™€ Spark Streamingì„ ì´ìš©í•œ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬.md
â”‚   â””â”€â”€ 05. Metabaseë¥¼ í™œìš©í•œ ë°ì´í„° ì‹œê°í™” (BI) êµ¬ì¶•.md
â”œâ”€â”€ img/
â”œâ”€â”€ postgres/               # DB ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ scripts/                # Spark ë° Kafka Python ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ kafka_producer.py
â”‚   â”œâ”€â”€ spark_load_patients.py
â”‚   â””â”€â”€ spark_streaming.py
â”œâ”€â”€ docker-compose.yml      # ì „ì²´ ì„œë¹„ìŠ¤ ì •ì˜
â””â”€â”€ Dockerfile              # Airflow ì»¤ìŠ¤í…€ ì´ë¯¸ì§€ (Spark, dbt ë¼ì´ë¸ŒëŸ¬ë¦¬ í¬í•¨)
```