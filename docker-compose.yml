version: '3.8'

services:
  # 1. Postgres
  postgres:
    image: postgres:13
    container_name: de_project_postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow_db"]
      interval: 5s
      timeout: 5s
      retries: 5

  # 2. Airflow Init
  airflow-init:
    build: .
    container_name: de_project_airflow_init
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow_db
      # üåü [Ï∂îÍ∞Ä] ÎπÑÎ∞ÄÌÇ§ ÏÑ§Ï†ï (403 ÏóêÎü¨ Ìï¥Í≤∞)
      - AIRFLOW__WEBSERVER__SECRET_KEY=my_secret_key
    command:
      - bash
      - -c
      - |
        airflow db init && \
        airflow users create \
          --username admin \
          --password admin \
          --firstname Anonymous \
          --lastname User \
          --role Admin \
          --email admin@example.org

  # 3. Airflow Webserver
  airflow-webserver:
    build: .
    container_name: de_project_airflow_webserver
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./dbt:/opt/airflow/dbt
      - ./scripts:/opt/airflow/scripts
      # üåü [Î≥µÍµ¨] Î°úÍ∑∏ Ìè¥Îçî Ïó∞Í≤∞! (Ïù¥Ï†ú ÌååÏùºÏù¥ Î≥¥Ïùº Í≤ÅÎãàÎã§)
      - ./logs:/opt/airflow/logs
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow_db
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      # üåü [Ï∂îÍ∞Ä] ÎπÑÎ∞ÄÌÇ§ ÏÑ§Ï†ï
      - AIRFLOW__WEBSERVER__SECRET_KEY=my_secret_key
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  # 4. Airflow Scheduler
  airflow-scheduler:
    build: .
    container_name: de_project_airflow_scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./dbt:/opt/airflow/dbt
      - ./scripts:/opt/airflow/scripts
      # üåü [Î≥µÍµ¨] Î°úÍ∑∏ Ìè¥Îçî Ïó∞Í≤∞!
      - ./logs:/opt/airflow/logs
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow_db
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      # üåü [Ï∂îÍ∞Ä] ÎπÑÎ∞ÄÌÇ§ ÏÑ§Ï†ï
      - AIRFLOW__WEBSERVER__SECRET_KEY=my_secret_key
    command: scheduler

  # 5. Spark Master
  spark-master:
    image: apache/spark:3.5.1-scala2.12-java17-python3-ubuntu
    container_name: de_project_spark_master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8081:8080"
      - "7077:7077"
    volumes:
      - ./scripts:/opt/spark/work-dir/scripts
      - ./data:/opt/spark/work-dir/data

  # 6. Spark Worker
  spark-worker:
    image: apache/spark:3.5.1-scala2.12-java17-python3-ubuntu
    container_name: de_project_spark_worker
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    volumes:
      - ./scripts:/opt/spark/work-dir/scripts
      - ./data:/opt/spark/work-dir/data

volumes:
  postgres_data: