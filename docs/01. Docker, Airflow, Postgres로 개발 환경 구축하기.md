# Step 1: Docker, Airflow, Postgres로 개발 환경 구축하기

이 프로젝트의 목표는 여러 데이터 엔지니어링 스택들을 로컬환경에서 테스트해보며 학습하는 것임. 1단계에서는 이 모든 도구를 격리된 환경에서 실행하기 위해 Docker Compose를 사용함.

## 핵심 도구

* **Docker Compose:** 여러 개의 Docker 컨테이너(서비스)를 하나의 설정 파일(`docker-compose.yml`)로 정의하고 실행하는 도구
* **PostgreSQL:** Airflow의 메타데이터(DAG 정보, 실행 이력 등)를 저장하고, 동시에 우리가 변환할 데이터(Data Warehouse)를 저장할 데이터베이스
* **Apache Airflow:** 데이터 파이프라인을 만들고, 스케줄링하며, 모니터링하는 오케스트레이션 도구

## 1. `docker-compose.yml` 설정

이 파일은 우리 환경의 "설계도"입니다.

* **`postgres` 서비스:**
    * `postgres:13` 이미지를 사용합니다.
    * 이 컨테이너는 두 가지 역할을 합니다.
        1.  Airflow 메타데이터용 `airflow_db` (Airflow가 접속)
        2.  우리의 데이터 웨어하우스용 `analytics_db` (dbt가 접속)
    * `volumes`의 `init-db.sh` 스크립트를 통해 `analytics_db`가 컨테이너 시작 시 자동으로 생성되도록 했습니다.
    * `5432` 포트를 로컬 PC와 연결해 `psql` 등으로 직접 접속할 수 있게 합니다.

* **`airflow-init` 서비스:**
    * Airflow DB를 초기화(`db init`)하고 `admin` 계정을 생성하는 일회성 작업입니다.

* **`airflow-webserver` / `airflow-scheduler` 서비스:**
    * Airflow의 핵심 컴포넌트입니다.
    * **중요한 설정 (Volumes):**
        * `./dags:/opt/airflow/dags`
        * `./dbt:/opt/airflow/dbt`
        * `./data:/opt/airflow/data`
        * 이 설정 덕분에 로컬 PC에서 `dags` 폴더의 `.py` 파일이나 `dbt` 폴더의 `.sql` 파일을 수정하면, **별도 빌드 없이** 컨테이너 내부의 Airflow가 즉시 변경사항을 감지합니다.
    * **중요한 설정 (`_PIP_ADDITIONAL_REQUIREMENTS`):**
        * Airflow 컨테이너가 시작할 때 2단계에서 필요한 Python 라이브러리(`pandas`, `dbt-postgres`)를 자동으로 설치해 줍니다.
        * (3단계에서 Spark 연동을 위해 이 부분에 `apache-airflow-providers-spark`를 추가하다가 버전 충돌 문제를 겪었습니다.)

## 2. `postgres/init-db.sh`의 역할

`docker-compose.yml`은 `postgres` 컨테이너가 시작할 때 `POSTGRES_DB` 환경 변수에 지정된 DB(`airflow_db`) 하나만 자동으로 생성합니다.

우리는 dbt가 사용할 별도의 `analytics_db`가 필요했기 때문에, `/docker-entrypoint-initdb.d/` 디렉터리에 `.sh` 스크립트를 마운트하는 Postgres 이미지의 기능을 활용했습니다. 이 위치에 마운트된 `init-db.sh`는 `analytics_db`가 존재하지 않으면 새로 생성하는 SQL을 실행합니다.

## 3. 실행 및 확인

1.  터미널에서 `docker-compose.yml`이 있는 루트 폴더에서 다음을 실행합니다.
    ```bash
    # --build: _PIP... 가 변경되었으므로 Airflow 이미지를 다시 빌드합니다.
    # -d: 백그라운드에서 실행합니다.
    docker-compose up --build -d
    ```

2.  웹 브라우저에서 `http://localhost:8080`에 접속하여 Airflow UI가 뜨는지 확인합니다.
    (ID: `admin` / PW: `admin`)